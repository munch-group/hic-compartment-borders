{
  "hash": "f1d870f0457777bb920cc9045eaf0887",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: GWF workflow\nexecute:\n  eval: false\n---\n\nr\"\"\"\n\nExample workflow using mapping between intput and output of each target. \nIt is made to show all the ways information may be passed through an workflow.\n\n```plaintext\n                        input_file1.txt                        input_file2.txt\n                                                                                                                \nfile label:             'raw_path'                              'raw_path'                                \n                            |                                       |                                  \n                            |                                       |                         \ntemplate:               uppercase_names                         uppercase_names                         \n                            |                                       |                          \n                            |                                       |                         \nfile label:            'uppercased_path'                       'uppercased_path'                         \n                            |                                       |                          \n                            |                                       |                         \ntemplate:                divide_names                            divide_names                         \n                         /          \\                            /          \\                          \n                        /            \\                          /            \\                         \nfile label:    'filt_me_path'  'filt_other_path'      'filt_me_path'  'filt_other_path'                         \n                        \\           /                           \\           /                         \n                         \\         /                             \\         /                         \ntemplate:                 unique_names                            unique_names                         \n                           |      |                                |      |  \n                           |      |                                |      |  \nfile label:      'uniq_me_path'  'uniq_other_path'       'uniq_me_path'  'uniq_other_path'\n                            \\            \\                        /           /\n                             \\            - - - - - - - - - - - / - - -     /  \n                              \\  / - - - - - - - -- - - - - - -         \\  /\n                               |                                          |                          \nfile label:     (collected) 'uniq_me_paths'              (collected) 'uniq_other_paths'                         \n                               |                                          |\n                               |                                          |\ntemplate:                   merge_names                                merge_names\n                               |                                          |                          \n                               |                                          |                          \nfile label:                'output_path'                              'output_path'                         \n```\n\n\"\"\"\n\n## Imports and utility functions\n\n::: {#290f7529 .cell execution_count=1}\n``` {.python .cell-code}\nimport os\nfrom pathlib import Path\nfrom gwf import Workflow, AnonymousTarget\nfrom gwf.workflow import collect\nimport glob\n```\n:::\n\n\nInstantiate the workflow with the name of the project folder:\n\n::: {#ff66995a .cell execution_count=2}\n``` {.python .cell-code}\n# instantiate the workflow\ngwf = Workflow(defaults={'account': 'your-project-folder-name'})\n```\n:::\n\n\nUtility functions:\n\n::: {#48388a08 .cell execution_count=3}\n``` {.python .cell-code}\n# utility function\ndef modify_path(path, **kwargs):\n    \"\"\"\n    Utility function for modifying file paths substituting\n    the directory (dir), base name (base), or file suffix (suffix).\n    \"\"\"\n    for key in ['dir', 'base', 'suffix']:\n        kwargs.setdefault(key, None)\n    assert len(kwargs) == 3\n\n    par, name = os.path.split(path)\n    name_no_suffix, suf = os.path.splitext(name)\n    if type(kwargs['suffix']) is str:\n        suf = kwargs['suffix']\n    if kwargs['dir'] is not None:\n        par = kwargs['dir']\n    if kwargs['base'] is not None:\n        name_no_suffix = kwargs['base']\n\n    new_path = os.path.join(par, name_no_suffix + suf)\n    if type(kwargs['suffix']) is tuple:\n        assert len(kwargs['suffix']) == 2\n        new_path, nsubs = re.subn(r'{}$'.format(kwargs['suffix'][0]), kwargs['suffix'][1], new_path)\n        assert nsubs == 1, nsubs\n    return new_path\n```\n:::\n\n\n## Template functions:\n\n::: {#b7ffeb1b .cell execution_count=4}\n``` {.python .cell-code}\n# task template function\ndef uppercase_names(raw_path): \n    \"\"\"\n    Formats names to uppercase.\n    \"\"\"\n    # dir for files produces by task\n    output_dir = 'steps/upper_cased'\n    # path of output file\n    uppercased_path = modify_path(raw_path, dir=output_dir, suffix='_uppercased.txt')\n\n    # input specification\n    inputs = [raw_path]\n    # output specification mapping a label to each file\n    outputs = {'uppercased_path': uppercased_path}\n    # resource specification\n    options = {'memory': '8g', 'walltime': '00:10:00'} \n\n    # tmporary output file path\n    tmp_uppercased_path = modify_path(raw_path, dir='/tmp')\n\n    # commands to run in task (bash script)\n    # we write to a tmp file and move that to the output directory \n    # only if the command succeds (the && takes care of that)\n    spec = f\"\"\"\n    mkdir -p {output_dir}\n    cat {raw_path} | tr [:lower:] [:upper:] > {tmp_uppercased_path} &&\n        mv {tmp_uppercased_path} {uppercased_path}\n    \"\"\"\n    # return target\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\n# task template function\ndef divide_names(uppercased_path, me=None):\n    \"\"\"\n    Splits names into two files. One with my name and one with other names.\n    \"\"\"\n    # uppercased version of the me argument\n    uppercased_me = me.upper()\n\n    # dir for files produces by task\n    output_dir = 'steps/filtered_names'\n    # path of output file with names matching me\n    filt_me_path = modify_path(uppercased_path, dir=output_dir, suffix=f'_{me}.txt')\n    # path of output file with other names\n    filt_other_path = modify_path(uppercased_path, dir=output_dir, suffix=f'_not_{me}.txt')\n\n    # input specification\n    inputs = [uppercased_path]\n    # output specification mapping a label to each file\n    outputs = {'filt_me_path': filt_me_path, 'filt_other_path': filt_other_path}\n    # resource specification\n    options = {'memory': '8g', 'walltime': '00:10:00'} \n\n    # tmporary output file paths\n    tmp_filt_me_path = modify_path(filt_me_path, dir='/tmp')\n    tmp_filt_other_path = modify_path(filt_other_path, dir='/tmp')\n\n    # commands to run in task (bash script)\n    # we write to tmp files and move them to the output directory \n    # only if the command succeds (the && takes care of that)\n    spec = f\"\"\"\n    mkdir -p {output_dir}    \n    grep {uppercased_me} {uppercased_path} > {tmp_filt_me_path} &&  \n        grep -v {uppercased_me} {uppercased_path} > {tmp_filt_other_path} &&  \n        mv {tmp_filt_me_path} {filt_me_path} &&  \n        mv {tmp_filt_other_path} {filt_other_path}\n    \"\"\"\n    # return target\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\n# task template function\ndef unique_names(filt_me_path, filt_other_path): \n    \"\"\"\n    Extracts unique names from a file.\n    \"\"\"\n    # dir for files produces by task\n    output_dir = 'steps/unique_names'\n    # path of output file with unique names matching me\n    uniq_me_path = modify_path(filt_me_path, dir=output_dir, suffix='_unique.txt')\n    # path of output file with unique other names\n    uniq_other_path = modify_path(filt_other_path, dir=output_dir, suffix='_unique.txt')\n\n    # input specification\n    inputs = [filt_me_path, filt_other_path]\n    # output specification mapping a label to each file\n    outputs = {'unique_me_path': uniq_me_path, 'unique_other_path': uniq_other_path}\n    # resource specification\n    options = {'memory': '8g', 'walltime': '00:10:00'} \n\n    # tmporary output file paths\n    tmp_uniq_me_path = modify_path(uniq_me_path, dir='/tmp')\n    tmp_uniq_other_path = modify_path(uniq_other_path, dir='/tmp')\n\n    # commands to run in task (bash script)\n    # we write to tmp files and move them to the output directory \n    # only if the command succeds (the && takes care of that)\n    spec = f\"\"\"\n    mkdir -p {output_dir}    \n    sort {filt_me_path} | uniq > {tmp_uniq_me_path} && \n        sort {filt_other_path} | uniq > {tmp_uniq_other_path} && \n        mv {tmp_uniq_me_path} {uniq_me_path} && \n        mv {tmp_uniq_other_path} {uniq_other_path}\n    \"\"\"\n    # return target\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n\n# task template function\ndef merge_names(paths, output_path): \n    \"\"\"\n    Merges names from many files.\n    \"\"\"\n    # dir for files produces by task\n    output_dir = modify_path(output_path, base='', suffix='')\n\n    # input specification\n    inputs = [paths]\n    # output specification mapping a label to the file\n    outputs = {'path': output_path}\n\n    # tmporary output file path\n    tmp_output_path =  modify_path(output_path, dir='/tmp')\n\n    # resource specification\n    options = {'memory': '8g', 'walltime': '00:10:00'} \n\n    # commands to run in task (bash script)\n    # we write to tmp files and move them to the output directory \n    # only if the command succeds (the && takes care of that)\n    spec = f\"\"\"\n    mkdir -p {output_dir}\n    cat {' '.join(paths)} > {tmp_output_path} && \n        mv {tmp_output_path} {output_path}\n    \"\"\"\n    # return target\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n\n# task template function\ndef run_notebook(path, dependencies, memory='8g', walltime='00:10:00', cores=1):    \n    \"\"\"\n    Executes a notebook inplace and saves the output.\n    \"\"\"\n    # path of output sentinel file\n    sentinel = modify_path(path, base=f'.{str(Path(path).name)}', suffix='.sentinel')\n    # sentinel = path.parent / f'.{path.name}'\n\n    # input specification\n    inputs = [path] + dependencies\n    # output specification mapping a label to each file\n    outputs = {'sentinel': sentinel}\n    # resource specification\n    options = {'memory': memory, 'walltime': walltime, 'cores': cores} \n\n    # commands to run in task (bash script)\n    spec = f\"\"\"\n    jupyter nbconvert --to notebook --execute --inplace {path} && touch {sentinel}\n    \"\"\"\n    # return target\n    return AnonymousTarget(inputs=inputs, outputs=outputs, options=options, spec=spec)\n```\n:::\n\n\n## Workflow:\n\n::: {#2fd5d5ea .cell execution_count=5}\n``` {.python .cell-code}\n# instantiate the workflow\ngwf = Workflow(defaults={'account': 'your-project-folder-name'})\n\n# input files for workflow\ninput_file_names = ['data/input_file1.txt', 'data/input_file2.txt']\n\n# workflow parameter\nmyname = 'Kasper'\n\n# run an uppercase_names task for each input file\nuppercase_names_targets = gwf.map(uppercase_names, input_file_names)\n\n# run an divide_names task for each output file from uppercase_names\nfilter_names_targets = gwf.map(divide_names, uppercase_names_targets.outputs, extra=dict(me=myname))\n\n# run an unique_names task for each output file from divide_names\nunique_names_targets = gwf.map(unique_names, filter_names_targets.outputs)\n\n# collect the outputs labelled 'unique_me_path' from all the outputs of unique_names \ncollected_outputs = collect(unique_names_targets.outputs, ['unique_me_path'])\n\n# create a single task to merge all those files into one\nmerge_me_target = gwf.target_from_template(\n    'merge_not_me_name_files',\n    merge_names(collected_outputs['unique_me_paths'], \"results/merged_me_names.txt\")\n    )\n\n# collect the outputs labelled 'unique_other_path' from all the outputs of unique_names \ncollected_outputs = collect(unique_names_targets.outputs, ['unique_other_path'])\n\n# create a single task to merge all those files into one\nmerge_other_target = gwf.target_from_template(\n    'merge_me_name_files',\n    merge_names(collected_outputs['unique_other_paths'], \"results/merged_not_me_names.txt\")\n    )\n\n# make notebooks depend on all output files from workflow\nnotebook_dependencies = []\nfor x in gwf.targets.values():\n    outputs = x.outputs\n    if type(outputs) is dict:\n        for o in outputs.values():\n            notebook_dependencies.append(o)\n    elif type(outputs) is list:\n        notebook_dependencies.extend(outputs)\n\n#  run notebooks in sorted order nb01_, nb02_, ...\nfor path in glob.glob('notebooks/*.ipynb'):\n    target = gwf.target_from_template(\n        os.path.basename(path), run_notebook(path, notebook_dependencies))\n    # make notebooks depend on all previous notebooks\n    notebook_dependencies.append(target.outputs['sentinel'])\n```\n:::\n\n\n",
    "supporting": [
      "master_workflow_files"
    ],
    "filters": [],
    "includes": {}
  }
}